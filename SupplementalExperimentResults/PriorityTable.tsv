condition\Priority	EA-NC-DG-NW	EA-NC-EG-NW	EA-NC-NG-NW	EA-NC-VG-NW	EA-SC-DG-NW	EA-SC-EG-NW	RA-NC-EG-NW	RA-NC-NG-NW	RA-SC-DG-NW	RA-SC-NG-NW	OA-NC-DG-NW	OA-NC-EG-EW	OA-NC-NG-NW	OA-SC-DG-NW	OA-SC-EG-EW	OA-SC-NG-NW	XA-NC-NG-NW																																																																																						
1st	trainable=True	trainable=True	trainable=True	trainable=True	trainable=True	trainable=True	block type=xception	block type=xception	learning rate=0.0001	learning rate=0.01	block type=xception	num blocks=1	block type=xception	block type=xception	num blocks=3	block type=xception	trainable=True																																																																																						
2nd	imagenet size=True	block type=xception	block type=xception	imagenet size=True	imagenet size=True	learning rate=0.01	trainable=True	trainable=True	trainable=True	trainable=True	filters 1 0=256	num layers=2	separable=False	learning rate=0.01	block type=xception	optimizer=adam weight decay	imagenet size=True																																																																																						
3rd	block type=xception	imagenet size=True	imagenet size=True	block type=xception	block type=xception	imagenet size=True	imagenet size=True	imagenet size=True	learning rate=0.001	learning rate=0.1	optimizer=adam weight decay	optimizer=sgd	optimizer=adam weight decay	learning rate=0.001	num layers=2	end learning rate=1e=5	pretrained=True																																																																																						
4th	optimizer=adam weight decay	version=b7	double step=True	momentum=0.1	momentum=0.1	block type=xception	augment=False	optimizer=adam weight decay	block type=xception	learning rate=0.001	end learning rate=1e=5	block type=xception	end learning rate=1e=5	optimizer=sgd	separable=True	optimizer=nadam	optimizer=adam weight decay																																																																																						
5th	optimizer=nadam	optimizer=adam weight decay	dropout=0.5	momentum=0.5	momentum=0.5	optimizer=adam	vertical flip=False	dropout=0.5	learning rate=2e=05	optimizer=adam weight decay	optimizer=nadam	momentum=0.1	dropout=0.5	momentum=0.1	reduction type=global max	learning rate=0.01	dropout=0.5																																																																																						
6th	end learning rate=1e=5	end learning rate=1e=5	triple step=True	learning rate=0.0001	learning rate=0.001	optimizer=adam weight decay	pretrained=False	end learning rate=1e=5	learning rate=1e=05	end learning rate=1e=5	learning rate=0.001	separable=True	optimizer=nadam	momentum=0.5	reduction type=global avg	learning rate=0.1	end learning rate=1e=5																																																																																						
7th	trainable=False	optimizer=nadam	version=b7	momentum=0.9	momentum=0.9	end learning rate=1e=5	rotation factor=0.0	learning rate=0.1	learning rate=0.01	optimizer=nadam	max pooling=True	learning rate=0.1	block type=resnet	learning rate=0.0001	max pooling=True	optimizer=adam	learning rate=0.0001																																																																																						
8th	double step=True	double step=True	pretrained=False	momentum=0.99	momentum=0.99	dropout=0.5	translation factor=0.0	optimizer=nadam	optimizer=sgd	block type=xception	block type=resnet	momentum=0.5	reduction type=global max	num layers=1	block type=resnet	block type=resnet	reduction type=global max																																																																																						
9th	triple step=True	triple step=True	block type=resnet	optimizer=sgd	optimizer=sgd	optimizer=nadam	horizontal flip=True	pretrained=False	momentum=0.1	optimizer=adam	dropout=0.5	momentum=0.9	learning rate=0.001	learning rate=2e=05	normalize=True	learning rate=0.001	double step=True																																																																																						
10th	pretrained=True	dropout=0.5	reduction type=global max	learning rate=0.001	optimizer=adam weight decay	momentum=0.99	zoom factor=0.1	learning rate=0.01	momentum=0.5	learning rate=0.0001	vertical flip=False	momentum=0.99	augment=False	num blocks=2	normalize=False	separable=False	reduction type=global avg																																																																																						
11th	block type=resnet	learning rate=0.001	reduction type=global avg	block type=resnet	end learning rate=1e=5	learning rate=0.001	normalize=True	reduction type=global max	trainable=False	momentum=0.99	filters 2 0=512	augment=False	vertical flip=False	momentum=0.9	kernel size=5	learning rate=0.0001	optimizer=adam																																																																																						
12th	dropout=0.5	block type=resnet	version=b4	optimizer=adam weight decay	optimizer=nadam	block type=resnet	contrast factor=0.0	reduction type=global avg	dropout=0.5	imagenet size=True	filters 2 0=256	block type=resnet	num layers=1	learning rate=1e=05	kernel size=3	reduction type=global max	triple step=True																																																																																						
13th	version=b2	learning rate=0.0001	dropout=0.25	end learning rate=1e=5	learning rate=0.0001	momentum=0.9	reduction type=global max	augment=False	momentum=0.9	momentum=0.9	separable=False	vertical flip=False	filters 1 0=512	momentum=0.99	kernel size=7	augment=contrast factor=0.1	dropout=0.25																																																																																						
14th	learning rate=0.1	optimizer=adam	rotation factor=0.0	optimizer=nadam	block type=resnet	learning rate=0.1	reduction type=global avg	dropout=0.25	momentum=0.99	learning rate=2e=05	rotation factor=0.0	kernel size=5	filters 1 1=512	separable=False	num blocks=2	filters 1 1=64	block type=efficient																																																																																						
15th	version=b4	pretrained=False	translation factor=0.1	version=b1	learning rate=2e=05	version=b0	contrast factor=0.1	normalize=True	optimizer=adam weight decay	pretrained=False	filters 2 0=128	reduction type=global max	filters 2 0=512	filters 2 1=512	filters 0 0=16	contrast factor=0.1	imagenet size=False																																																																																						
16th	version=b1	dropout=0.25	augment=False	version=b0	learning rate=0.01	reduction type=global max	reduction type=flatten	momentum=0.99	augment=translation factor=0.0	dropout=0.5	filters 0 0=512	dropout=0.5	num blocks=2	augment=rotation factor=0.0	filters 0 0=128	kernel size=5	block type=resnet																																																																																						
17th	imagenet size=False	version=b0	horizontal flip=False	dropout=0.5	learning rate=1e=05	learning rate=1e=05	normalize=False	momentum=0.9	translation factor=0.0	dropout=0.25	filters 0 1=128	max pooling=False	rotation factor=0.0	rotation factor=0.0	filters 0 0=32	num layers=1	optimizer=nadam																																																																																						
18th	version=b3	freeze=all	zoom factor=0.0	learning rate=0.01	version=b6	dropout=0.25	zoom factor=0.0	optimizer=adam	augment=vertical flip=True	reduction type=global max	zoom factor=0.1	rotation factor=0.0	activation=tanh	filters 1 1=32	filters 0 0=64	rotation factor=0.1	freeze=all																																																																																						
19th	normalize=True	freeze=no	freeze=all	normalize=False	reduction type=global max	version=b2	horizontal flip=False	dropout=0.0	vertical flip=True	normalize=True	kernel size=5	initial=lecun uniform	learning rate=0.01	filters 2 1=64	filters 0 0=256	dropout=0.5	learning rate=0.001																																																																																						
20th	freeze=bn	freeze=bn	freeze=bn	reduction type=global max	dropout=0.5	normalize=False	augment=vertical flip=False	normalize=False	end learning rate=1e=5	reduction type=global avg	activation=selu	activation=tanh	initial=he uniform	augment=horizontal flip=False	filters 0 0=512	kernel size=3	pretrained=False																																																																																						
21th	freeze=all	reduction type=global max	normalize=False	learning rate=2e=05	version=b3	learning rate=2e=05	translation factor=0.1	augment=translation factor=0.1	optimizer=nadam	normalize=False	initial=he uniform	dropout=0.25	filters 0 0=512	horizontal flip=False	filters 0 1=16	filters 1 0=32	freeze=bn																																																																																						
22th	freeze=no	version=b1	vertical flip=True	version=b6	version=b2	version=b6	rotation factor=0.1	augment=horizontal flip=False	augment=contrast factor=0.1	dropout=0.0	reduction type=global max	translation factor=0.0	activation=selu	num blocks=1	filters 0 1=512	filters 0 0=32	freeze=no																																																																																						
23th	reduction type=global max	normalize=True	freeze=no	version=b2	version=b5	version=b3	augment=rotation factor=0.0	augment=vertical flip=False	contrast factor=0.1	reduction type=flatten	num layers=2	contrast factor=0.1	filters 1 0=256	block type=resnet	filters 0 1=32	num blocks=2	dropout=0.0																																																																																						
24th	reduction type=global avg	normalize=False	augment=rotation factor=0.0	version=b7	reduction type=global avg	version=b4	pretrained=True	augment=rotation factor=0.1	pretrained=False	pretrained=True	activation=tanh	filters 0 0=512	initial=lecun uniform	filters 1 1=256	filters 0 1=64	filters 0 1=16	normalize=True																																																																																						
25th	learning rate=0.01	reduction type=global avg	augment=translation factor=0.1	reduction type=global avg	version=b7	version=b1	vertical flip=True	augment=zoom factor=0.1	augment=horizontal flip=False	learning rate=1e=05	initial=lecun uniform	initial=he uniform	filters 2 1=512	optimizer=adam	filters 0 1=128	augment=rotation factor=0.1	lr ratio=1.0																																																																																						
26th	version=b0	reduction type=flatten	contrast factor=0.1	version=b3	optimizer=adam	reduction type=global avg	augment=zoom factor=0.1	augment=contrast factor=0.0	horizontal flip=False	momentum=0.5	augment=translation factor=0.0	kernel size=3	translation factor=0.0	kernel size=5	filters 0 1=256	filters 0 1=512	momentum=0.99																																																																																						
27th	reduction type=flatten	learning rate=0.01	version=b1	normalize=True	version=b4	version=b5	augment=translation factor=0.0	momentum=0.5	reduction type=global max	imagenet size=False	augment=horizontal flip=True	activation=selu	filters 1 1=256	max pooling=True	filters 1 0=16	augment=zoom factor=0.1	normalize=False																																																																																						
28th	lr ratio=1.0	dropout=0.0	augment=horizontal flip=False	learning rate=0.1	dropout=0.25	version=b7	augment=horizontal flip=True	reduction type=flatten	augment=zoom factor=0.0	momentum=0.1	augment=vertical flip=False	normalize=True	max pooling=False	filters 1 0=64	filters 1 0=512	num blocks=3	momentum=0.9																																																																																						
29th	normalize=False	version=b3	augment=zoom factor=0.0	optimizer=adam	normalize=False	dropout=0.0	augment=vertical flip=True	momentum=0.1	dropout=0.25	optimizer=sgd	augment=rotation factor=0.0	horizontal flip=True	filters 2 1=256	filters 0 0=16	filters 1 0=32	filters 0 0=16	epoch ratio=0.2																																																																																						
30th	momentum=0.99	version=b4	version=b3	dropout=0.25	dropout=0.0	normalize=True	augment=rotation factor=0.1	optimizer=sgd	zoom factor=0.0	block type=efficient	augment=zoom factor=0.1	learning rate=0.01	filters 1 0=128	filters 1 0=16	filters 1 0=64	reduction type=global avg	end learning rate=2e=06																																																																																						
31th	momentum=0.9	lr ratio=1.0	contrast factor=0.0	version=b5	version=b0	learning rate=0.0001	augment=zoom factor=0.0	learning rate=0.001	optimizer=adam	block type=vanilla	augment=contrast factor=0.1	filters 0 1=512	kernel size=5	normalize=True	filters 1 0=128	contrast factor=0.0	weight decay rate=0.01																																																																																						
32th	learning rate=0.001	version=b2	vertical flip=False	reduction type=flatten	normalize=True	reduction type=flatten	augment=contrast factor=0.0	learning rate=0.0001	augment=rotation factor=0.0	/	normalize=False	zoom factor=0.1	filters 2 0=256	filters 1 0=128	filters 1 0=256	vertical flip=False	end learning rate=0.0																																																																																						
33th	dropout=0.25	version=b6	normalize=True	learning rate=1e=05	version=b1	imagenet size=False	augment=contrast factor=0.1	pretrained=True	rotation factor=0.0	/	filters 0 0=128	filters 0 0=128	filters 2 1=128	filters 1 1=512	filters 1 1=16	filters 0 0=64	weight decay rate=0.1																																																																																						
34th	momentum=0.5	epoch ratio=0.2	version=b2	dropout=0.0	imagenet size=False	block type=vanilla	augment=horizontal flip=False	block type=vanilla	normalize=True	/	dropout=0.25	optimizer=adam weight decay	filters 0 0=256	optimizer=adam weight decay	filters 1 1=256	augment=zoom factor=0.0	weight decay rate=0.001																																																																																						
35th	version=b5	version=b5	lr ratio=1.0	version=b4	reduction type=flatten	momentum=0.5	augment=translation factor=0.1	block type=efficient	augment=translation factor=0.1	/	filters 2 0=64	optimizer=nadam	filters 2 0=64	reduction type=global max	filters 1 1=32	translation factor=0.0	end learning rate=0.0001																																																																																						
36th	epoch ratio=0.2	end learning rate=2e=06	augment=vertical flip=True	block type=vanilla	learning rate=0.1	momentum=0.1	imagenet size=False	imagenet size=False	augment=horizontal flip=True	/	augment=horizontal flip=False	end learning rate=1e=5	filters 2 0=128	end learning rate=1e=5	filters 1 1=64	max pooling=True	epoch ratio=0.3																																																																																						
37th	momentum=0.1	weight decay rate=0.005	reduction type=flatten	/	block type=vanilla	optimizer=sgd	block type=efficient	learning rate=2e=05	augment=vertical flip=False	/	augment=translation factor=0.1	zoom factor=0.0	horizontal flip=False	optimizer=nadam	filters 1 1=128	augment=translation factor=0.0	epoch ratio=0.1																																																																																						
38th	optimizer=sgd	end learning rate=1e=06	augment=contrast factor=0.1	/	/	/	block type=vanilla	learning rate=1e=05	augment=rotation factor=0.1	/	kernel size=7	filters 0 1=32	filters 0 1=512	reduction type=global avg	block type=efficient	filters 0 1=64	weight decay rate=0.05																																																																																						
39th	weight decay rate=0.01	momentum=0.99	zoom factor=0.1	/	/	/	/	trainable=False	augment=zoom factor=0.1	/	contrast factor=0.1	augment=vertical flip=False	filters 1 0=64	kernel size=3	filters 1 1=512	horizontal flip=False	end learning rate=1e=06																																																																																						
40th	end learning rate=1e=06	end learning rate=0.0	horizontal flip=True	/	/	/	/	/	augment=contrast factor=0.0	/	reduction type=global avg	filters 0 1=128	normalize=False	dropout=0.25	max pooling=False	augment=False	weight decay rate=0.005																																																																																						
41th	end learning rate=2e=06	weight decay rate=0.01	augment=translation factor=0.0	/	/	/	/	/	reduction type=global avg	/	filters 1 1=32	filters 0 1=64	kernel size=7	dropout=0.0	reduction type=flatten	zoom factor=0.1	epoch ratio=0.5																																																																																						
42th	weight decay rate=0.05	epoch ratio=0.3	augment=horizontal flip=True	/	/	/	/	/	reduction type=flatten	/	num blocks=3	horizontal flip=False	dropout=0.25	kernel size=7	separable=False	augment=contrast factor=0.0	reduction type=flatten																																																																																						
43th	weight decay rate=0.005	weight decay rate=0.001	augment=vertical flip=False	/	/	/	/	/	normalize=False	/	filters 1 1=256	normalize=False	zoom factor=0.1	filters 0 0=32	num layers=1	augment=vertical flip=False	epoch ratio=0.4																																																																																						
44th	version=b6	end learning rate=0.0001	augment=rotation factor=0.1	/	/	/	/	/	augment=False	/	augment=contrast factor=0.0	filters 0 0=256	filters 1 1=128	filters 0 0=64	num blocks=1	filters 0 1=32	triple step=False																																																																																						
45th	weight decay rate=0.1	weight decay rate=0.05	augment=zoom factor=0.1	/	/	/	/	/	imagenet size=False	/	translation factor=0.0	dropout=0.0	contrast factor=0.0	filters 0 0=128	/	learning rate=1e=05	momentum=0.5																																																																																						
46th	epoch ratio=0.3	epoch ratio=0.1	augment=contrast factor=0.0	/	/	/	/	/	dropout=0.0	/	horizontal flip=True	translation factor=0.1	zoom factor=0.0	filters 0 0=256	/	filters 0 1=128	learning rate=2e=05																																																																																						
47th	end learning rate=0.0	weight decay rate=0.1	translation factor=0.0	/	/	/	/	/	rotation factor=0.1	/	filters 0 0=64	contrast factor=0.0	filters 2 1=64	filters 0 0=512	/	filters 1 1=16	momentum=0.1																																																																																						
48th	weight decay rate=0.001	epoch ratio=0.4	rotation factor=0.1	/	/	/	/	/	zoom factor=0.1	/	learning rate=0.0001	rotation factor=0.1	num blocks=1	filters 0 1=16	/	filters 0 0=512	optimizer=sgd																																																																																						
49th	dropout=0.0	momentum=0.9	version=b0	/	/	/	/	/	horizontal flip=True	/	filters 0 1=256	max pooling=True	contrast factor=0.1	filters 0 1=128	/	normalize=True	lr ratio=0.1																																																																																						
50th	learning rate=0.0001	epoch ratio=0.5	epoch ratio=0.2	/	/	/	/	/	pretrained=True	/	filters 1 1=64	filters 0 1=16	normalize=True	filters 0 1=32	/	filters 1 0=64	learning rate=0.01																																																																																						
51th	epoch ratio=0.1	pretrained=True	version=b6	/	/	/	/	/	contrast factor=0.0	/	horizontal flip=False	filters 0 0=32	horizontal flip=True	filters 0 1=64	/	filters 1 0=128	lr ratio=0.01																																																																																						
52th	epoch ratio=0.5	learning rate=2e=05	weight decay rate=0.01	/	/	/	/	/	vertical flip=False	/	translation factor=0.1	filters 0 0=64	filters 1 1=64	filters 0 1=256	/	filters 1 0=512	learning rate=1e=05																																																																																						
53th	end learning rate=0.0001	learning rate=1e=05	version=b5	/	/	/	/	/	translation factor=0.1	/	filters 0 1=64	reduction type=global avg	filters 0 0=128	filters 0 1=512	/	activation=selu	learning rate=0.1																																																																																						
54th	learning rate=1e=05	momentum=0.5	end learning rate=2e=06	/	/	/	/	/	block type=vanilla	/	num blocks=2	reduction type=flatten	dropout=0.0	filters 1 0=32	/	activation=tanh	block type=vanilla																																																																																						
55th	learning rate=2e=05	learning rate=0.1	weight decay rate=0.005	/	/	/	/	/	imagenet size=True	/	filters 1 0=128	kernel size=7	filters 0 1=128	filters 1 0=256	/	initial=he uniform	trainable=False																																																																																						
56th	optimizer=adam	block type=vanilla	epoch ratio=0.1	/	/	/	/	/	block type=efficient	/	filters 1 1=512	filters 0 1=256	filters 0 1=256	filters 1 0=512	/	initial=lecun uniform	/																																																																																						
57th	epoch ratio=0.4	momentum=0.1	end learning rate=1e=06	/	/	/	/	/	learning rate=0.1	/	filters 0 1=32	augment=translation factor=0.0	filters 0 0=64	filters 2 0=16	/	augment=horizontal flip=False	/																																																																																						
58th	lr ratio=0.1	lr ratio=0.1	weight decay rate=0.001	/	/	/	/	/	/	/	augment=zoom factor=0.0	augment=contrast factor=0.1	filters 0 1=64	filters 2 0=512	/	filters 1 0=256	/																																																																																						
59th	version=b7	optimizer=sgd	weight decay rate=0.05	/	/	/	/	/	/	/	filters 0 1=16	augment=horizontal flip=True	optimizer=adam	filters 2 0=32	/	filters 1 1=32	/																																																																																						
60th	block type=vanilla	lr ratio=0.01	end learning rate=0.0	/	/	/	/	/	/	/	reduction type=flatten	vertical flip=True	filters 0 0=32	filters 2 0=64	/	filters 1 1=512	/																																																																																						
61th	triple step=False	imagenet size=False	epoch ratio=0.4	/	/	/	/	/	/	/	filters 0 0=16	augment=translation factor=0.1	max pooling=True	filters 2 0=128	/	filters 1 0=16	/																																																																																						
62th	pretrained=False	triple step=False	epoch ratio=0.5	/	/	/	/	/	/	/	contrast factor=0.0	augment=horizontal flip=False	filters 0 1=32	filters 2 0=256	/	augment=translation factor=0.1	/																																																																																						
63th	lr ratio=0.01	trainable=False	weight decay rate=0.1	/	/	/	/	/	/	/	kernel size=3	augment=vertical flip=True	translation factor=0.1	filters 1 1=16	/	filters 1 1=256	/																																																																																						
64th	/	/	end learning rate=0.0001	/	/	/	/	/	/	/	augment=rotation factor=0.1	augment=rotation factor=0.0	filters 2 0=16	filters 1 1=128	/	normalize=False	/																																																																																						
65th	/	/	epoch ratio=0.3	/	/	/	/	/	/	/	filters 0 0=32	augment=zoom factor=0.1	kernel size=3	filters 2 1=16	/	filters 0 0=256	/																																																																																						
66th	/	/	dropout=0.0	/	/	/	/	/	/	/	filters 1 1=128	augment=contrast factor=0.0	filters 0 1=16	filters 2 1=32	/	filters 0 0=128	/																																																																																						
67th	/	/	lr ratio=0.1	/	/	/	/	/	/	/	normalize=True	augment=zoom factor=0.0	filters 2 0=32	filters 2 1=128	/	learning rate=2e=05	/																																																																																						
68th	/	/	block type=vanilla	/	/	/	/	/	/	/	augment=False	learning rate=0.001	learning rate=0.0001	filters 2 1=256	/	num blocks=1	/																																																																																						
69th	/	/	lr ratio=0.01	/	/	/	/	/	/	/	filters 2 0=32	augment=rotation factor=0.1	rotation factor=0.1	augment=False	/	reduction type=flatten	/																																																																																						
70th	/	/	imagenet size=False	/	/	/	/	/	/	/	num layers=1	block type=efficient	filters 1 0=16	augment=translation factor=0.1	/	zoom factor=0.0	/																																																																																						
71th	/	/	pretrained=True	/	/	/	/	/	/	/	filters 1 1=16	filters 0 0=16	filters 1 1=16	augment=translation factor=0.0	/	augment=vertical flip=True	/																																																																																						
72th	/	/	triple step=False	/	/	/	/	/	/	/	filters 2 0=16	learning rate=0.0001	filters 2 1=16	augment=horizontal flip=True	/	augment=horizontal flip=True	/																																																																																						
73th	/	/	trainable=False	/	/	/	/	/	/	/	filters 1 0=64	learning rate=1e=05	augment=rotation factor=0.0	augment=vertical flip=True	/	horizontal flip=True	/																																																																																						
74th	/	/	/	/	/	/	/	/	/	/	augment=vertical flip=True	learning rate=2e=05	augment=vertical flip=False	augment=vertical flip=False	/	filters 1 1=128	/																																																																																						
75th	/	/	/	/	/	/	/	/	/	/	zoom factor=0.0	separable=False	filters 1 0=32	augment=rotation factor=0.1	/	augment=rotation factor=0.0	/																																																																																						
76th	/	/	/	/	/	/	/	/	/	/	filters 0 1=512	num blocks=2	reduction type=global avg	augment=zoom factor=0.0	/	max pooling=False	/																																																																																						
77th	/	/	/	/	/	/	/	/	/	/	filters 0 0=256	num blocks=3	filters 0 0=16	augment=zoom factor=0.1	/	dropout=0.25	/																																																																																						
78th	/	/	/	/	/	/	/	/	/	/	rotation factor=0.1	num layers=1	augment=translation factor=0.0	augment=contrast factor=0.0	/	translation factor=0.1	/																																																																																						
79th	/	/	/	/	/	/	/	/	/	/	optimizer=adam	optimizer=adam	filters 1 1=32	augment=contrast factor=0.1	/	vertical flip=True	/																																																																																						
80th	/	/	/	/	/	/	/	/	/	/	separable=True	/	num layers=2	translation factor=0.0	/	filters 0 1=256	/																																																																																						
81th	/	/	/	/	/	/	/	/	/	/	dropout=0.0	/	vertical flip=True	translation factor=0.1	/	dropout=0.0	/																																																																																						
82th	/	/	/	/	/	/	/	/	/	/	filters 1 0=32	/	reduction type=flatten	vertical flip=False	/	kernel size=7	/																																																																																						
83th	/	/	/	/	/	/	/	/	/	/	vertical flip=True	/	num blocks=3	vertical flip=True	/	rotation factor=0.0	/																																																																																						
84th	/	/	/	/	/	/	/	/	/	/	filters 1 0=16	/	augment=horizontal flip=False	zoom factor=0.1	/	num layers=2	/																																																																																						
85th	/	/	/	/	/	/	/	/	/	/	max pooling=False	/	augment=contrast factor=0.0	zoom factor=0.0	/	separable=True	/																																																																																						
86th	/	/	/	/	/	/	/	/	/	/	learning rate=2e=05	/	augment=contrast factor=0.1	contrast factor=0.1	/	momentum=0.99	/																																																																																						
87th	/	/	/	/	/	/	/	/	/	/	momentum=0.99	/	filters 2 1=32	contrast factor=0.0	/	momentum=0.9	/																																																																																						
88th	/	/	/	/	/	/	/	/	/	/	momentum=0.9	/	augment=horizontal flip=True	dropout=0.5	/	block type=efficient	/																																																																																						
89th	/	/	/	/	/	/	/	/	/	/	num blocks=1	/	augment=zoom factor=0.1	activation=selu	/	momentum=0.5	/																																																																																						
90th	/	/	/	/	/	/	/	/	/	/	block type=efficient	/	augment=zoom factor=0.0	activation=tanh	/	momentum=0.1	/																																																																																						
91th	/	/	/	/	/	/	/	/	/	/	learning rate=1e=05	/	momentum=0.99	initial=he uniform	/	optimizer=sgd	/																																																																																						
92th	/	/	/	/	/	/	/	/	/	/	momentum=0.5	/	augment=rotation factor=0.1	initial=lecun uniform	/	/	/																																																																																						
93th	/	/	/	/	/	/	/	/	/	/	momentum=0.1	/	augment=translation factor=0.1	reduction type=flatten	/	/	/																																																																																						
94th	/	/	/	/	/	/	/	/	/	/	optimizer=sgd	/	momentum=0.9	filters 1 1=64	/	/	/																																																																																						
95th	/	/	/	/	/	/	/	/	/	/	learning rate=0.01	/	augment=vertical flip=True	normalize=False	/	/	/																																																																																						
96th	/	/	/	/	/	/	/	/	/	/	filters 1 0=512	/	momentum=0.5	max pooling=False	/	/	/																																																																																						
97th	/	/	/	/	/	/	/	/	/	/	learning rate=0.1	/	learning rate=2e=05	horizontal flip=True	/	/	/																																																																																						
98th	/	/	/	/	/	/	/	/	/	/	/	/	momentum=0.1	rotation factor=0.1	/	/	/																																																																																						
99th	/	/	/	/	/	/	/	/	/	/	/	/	optimizer=sgd	separable=True	/	/	/																																																																																						
100th	/	/	/	/	/	/	/	/	/	/	/	/	block type=efficient	learning rate=0.1	/	/	/																																																																																						
101th	/	/	/	/	/	/	/	/	/	/	/	/	learning rate=1e=05	block type=efficient	/	/	/																																																																																						
102th	/	/	/	/	/	/	/	/	/	/	/	/	separable=True	num blocks=3	/	/	/																																																																																						
103th	/	/	/	/	/	/	/	/	/	/	/	/	learning rate=0.1	num layers=2	/	/	/																																																																																						
																																																																																																							
																																																																																																							
																																																																																																							
																																																																																																							
																																																																																																							
																																																																																																							
																																																																																																							
																																																																																																							
																																																																																																							
																																																																																																							
																																																																																																							
																																																																																																							
																																																																																																							
																																																																																																							
																																																																																																							
																																																																																																							
																																																																																																							
																																																																																																							
																																																																																																							
																																																																																																							
																																																																																																							
																																																																																																							
																																																																																																							
																																																																																																							
																																																																																																							
																																																																																																							
																																																																																																							
																																																																																																							
																																																																																																							
																																																																																																							
																																																																																																							
																																																																																																							
																																																																																																							
																																																																																																							
																																																																																																							
																																																																																																							
																																																																																																							
																																																																																																							
																																																																																																							
																																																																																																							
																																																																																																							
																																																																																																							
																																																																																																							
																																																																																																							
																																																																																																							
condition	1th	2th	3th	4th	5th	6th	7th	8th	9th	10th	11th	12th	13th	14th	15th	16th	17th	18th	19th	20th	21th	22th	23th	24th	25th	26th	27th	28th	29th	30th	31th	32th	33th	34th	35th	36th	37th	38th	39th	40th	41th	42th	43th	44th	45th	46th	47th	48th	49th	50th	51th	52th	53th	54th	55th	56th	57th	58th	59th	60th	61th	62th	63th	64th	65th	66th	67th	68th	69th	70th	71th	72th	73th	74th	75th	76th	77th	78th	79th	80th	81th	82th	83th	84th	85th	86th	87th	88th	89th	90th	91th	92th	93th	94th	95th	96th	97th	98th	99th	100th	101th	102th	103th
efficient-normal-dying-normal	trainable-True	imagenet_size-True	block_type-xception	optimizer-adam_weight_decay	optimizer-nadam	end_learning_rate-1e-5	trainable-False	multi_step-True	triple_train-True	pretrained-True	block_type-resnet	dropout-0.5	version-b2	learning_rate-0.1	version-b4	version-b1	imagenet_size-False	version-b3	normalize-True	step_1_freeze-bn	step_1_freeze-all	step_1_freeze-no	reduction_type-global_max	reduction_type-global_avg	learning_rate-0.01	version-b0	reduction_type-flatten	step_2_lr_scale-1.0	normalize-False	momentum-0.99	momentum-0.9	learning_rate-0.001	dropout-0.25	momentum-0.5	version-b5	step_1_ratio-0.2	momentum-0.1	optimizer-sgd	weight_decay_rate-0.01	end_learning_rate-1e-06	end_learning_rate-2e-06	weight_decay_rate-0.05	weight_decay_rate-0.005	version-b6	weight_decay_rate-0.1	step_1_ratio-0.3	end_learning_rate-0.0	weight_decay_rate-0.001	dropout-0.0	learning_rate-0.0001	step_1_ratio-0.1	step_1_ratio-0.5	end_learning_rate-0.0001	learning_rate-1e-05	learning_rate-2e-05	optimizer-adam	step_1_ratio-0.4	step_2_lr_scale-0.1	version-b7	block_type-vanilla	triple_train-False	pretrained-False	step_2_lr_scale-0.01	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/
efficient-normal-explode-normal	trainable-True	block_type-xception	imagenet_size-True	version-b7	optimizer-adam_weight_decay	end_learning_rate-1e-5	optimizer-nadam	multi_step-True	triple_train-True	dropout-0.5	learning_rate-0.001	block_type-resnet	learning_rate-0.0001	optimizer-adam	pretrained-False	dropout-0.25	version-b0	step_1_freeze-all	step_1_freeze-no	step_1_freeze-bn	reduction_type-global_max	version-b1	normalize-True	normalize-False	reduction_type-global_avg	reduction_type-flatten	learning_rate-0.01	dropout-0.0	version-b3	version-b4	step_2_lr_scale-1.0	version-b2	version-b6	step_1_ratio-0.2	version-b5	end_learning_rate-2e-06	weight_decay_rate-0.005	end_learning_rate-1e-06	momentum-0.99	end_learning_rate-0.0	weight_decay_rate-0.01	step_1_ratio-0.3	weight_decay_rate-0.001	end_learning_rate-0.0001	weight_decay_rate-0.05	step_1_ratio-0.1	weight_decay_rate-0.1	step_1_ratio-0.4	momentum-0.9	step_1_ratio-0.5	pretrained-True	learning_rate-2e-05	learning_rate-1e-05	momentum-0.5	learning_rate-0.1	block_type-vanilla	momentum-0.1	step_2_lr_scale-0.1	optimizer-sgd	step_2_lr_scale-0.01	imagenet_size-False	triple_train-False	trainable-False	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/
efficient-normal-normal-normal	trainable-True	block_type-xception	imagenet_size-True	multi_step-True	dropout-0.5	triple_train-True	version-b7	pretrained-False	block_type-resnet	reduction_type-global_max	reduction_type-global_avg	version-b4	dropout-0.25	rotation_factor-0.0	translation_factor-0.1	augment-False	horizontal_flip-False	zoom_factor-0.0	step_1_freeze-all	step_1_freeze-bn	normalize-False	vertical_flip-True	step_1_freeze-no	augment-rotation_factor-0.0	augment-translation_factor-0.1	contrast_factor-0.1	version-b1	augment-horizontal_flip-False	augment-zoom_factor-0.0	version-b3	contrast_factor-0.0	vertical_flip-False	normalize-True	version-b2	step_2_lr_scale-1.0	augment-vertical_flip-True	reduction_type-flatten	augment-contrast_factor-0.1	zoom_factor-0.1	horizontal_flip-True	augment-translation_factor-0.0	augment-horizontal_flip-True	augment-vertical_flip-False	augment-rotation_factor-0.1	augment-zoom_factor-0.1	augment-contrast_factor-0.0	translation_factor-0.0	rotation_factor-0.1	version-b0	step_1_ratio-0.2	version-b6	weight_decay_rate-0.01	version-b5	end_learning_rate-2e-06	weight_decay_rate-0.005	step_1_ratio-0.1	end_learning_rate-1e-06	weight_decay_rate-0.001	weight_decay_rate-0.05	end_learning_rate-0.0	step_1_ratio-0.4	step_1_ratio-0.5	weight_decay_rate-0.1	end_learning_rate-0.0001	step_1_ratio-0.3	dropout-0.0	step_2_lr_scale-0.1	block_type-vanilla	step_2_lr_scale-0.01	imagenet_size-False	pretrained-True	triple_train-False	trainable-False	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/
efficient-normal-vanish-normal	trainable-True	imagenet_size-True	block_type-xception	momentum-0.1	momentum-0.5	learning_rate-0.0001	momentum-0.9	momentum-0.99	optimizer-sgd	learning_rate-0.001	block_type-resnet	optimizer-adam_weight_decay	end_learning_rate-1e-5	optimizer-nadam	version-b1	version-b0	dropout-0.5	learning_rate-0.01	normalize-False	reduction_type-global_max	learning_rate-2e-05	version-b6	version-b2	version-b7	reduction_type-global_avg	version-b3	normalize-True	learning_rate-0.1	optimizer-adam	dropout-0.25	version-b5	reduction_type-flatten	learning_rate-1e-05	dropout-0.0	version-b4	block_type-vanilla	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/
efficient-slow_converge-dying-normal	trainable-True	imagenet_size-True	block_type-xception	momentum-0.1	momentum-0.5	learning_rate-0.001	momentum-0.9	momentum-0.99	optimizer-sgd	optimizer-adam_weight_decay	end_learning_rate-1e-5	optimizer-nadam	learning_rate-0.0001	block_type-resnet	learning_rate-2e-05	learning_rate-0.01	learning_rate-1e-05	version-b6	reduction_type-global_max	dropout-0.5	version-b3	version-b2	version-b5	reduction_type-global_avg	version-b7	optimizer-adam	version-b4	dropout-0.25	normalize-False	dropout-0.0	version-b0	normalize-True	version-b1	imagenet_size-False	reduction_type-flatten	learning_rate-0.1	block_type-vanilla	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/
efficient-slow_converge-explode-normal	trainable-True	learning_rate-0.01	imagenet_size-True	block_type-xception	optimizer-adam	optimizer-adam_weight_decay	end_learning_rate-1e-5	dropout-0.5	optimizer-nadam	momentum-0.99	learning_rate-0.001	block_type-resnet	momentum-0.9	learning_rate-0.1	version-b0	reduction_type-global_max	learning_rate-1e-05	dropout-0.25	version-b2	normalize-False	learning_rate-2e-05	version-b6	version-b3	version-b4	version-b1	reduction_type-global_avg	version-b5	version-b7	dropout-0.0	normalize-True	learning_rate-0.0001	reduction_type-flatten	imagenet_size-False	block_type-vanilla	momentum-0.5	momentum-0.1	optimizer-sgd	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/
resnet-normal-explode-normal	block_type-xception	trainable-True	imagenet_size-True	augment-False	vertical_flip-False	pretrained-False	rotation_factor-0.0	translation_factor-0.0	horizontal_flip-True	zoom_factor-0.1	normalize-True	contrast_factor-0.0	reduction_type-global_max	reduction_type-global_avg	contrast_factor-0.1	reduction_type-flatten	normalize-False	zoom_factor-0.0	horizontal_flip-False	augment-vertical_flip-False	translation_factor-0.1	rotation_factor-0.1	augment-rotation_factor-0.0	pretrained-True	vertical_flip-True	augment-zoom_factor-0.1	augment-translation_factor-0.0	augment-horizontal_flip-True	augment-vertical_flip-True	augment-rotation_factor-0.1	augment-zoom_factor-0.0	augment-contrast_factor-0.0	augment-contrast_factor-0.1	augment-horizontal_flip-False	augment-translation_factor-0.1	imagenet_size-False	block_type-efficient	block_type-vanilla	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/
resnet-normal-normal-normal	block_type-xception	trainable-True	imagenet_size-True	optimizer-adam_weight_decay	dropout-0.5	end_learning_rate-1e-5	learning_rate-0.1	optimizer-nadam	pretrained-False	learning_rate-0.01	reduction_type-global_max	reduction_type-global_avg	augment-False	dropout-0.25	normalize-True	momentum-0.99	momentum-0.9	optimizer-adam	dropout-0.0	normalize-False	augment-translation_factor-0.1	augment-horizontal_flip-False	augment-vertical_flip-False	augment-rotation_factor-0.1	augment-zoom_factor-0.1	augment-contrast_factor-0.0	momentum-0.5	reduction_type-flatten	momentum-0.1	optimizer-sgd	learning_rate-0.001	learning_rate-0.0001	pretrained-True	block_type-vanilla	block_type-efficient	imagenet_size-False	learning_rate-2e-05	learning_rate-1e-05	trainable-False	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/
resnet-slow_converge-dying-normal	learning_rate-0.0001	trainable-True	learning_rate-0.001	block_type-xception	learning_rate-2e-05	learning_rate-1e-05	learning_rate-0.01	optimizer-sgd	momentum-0.1	momentum-0.5	trainable-False	dropout-0.5	momentum-0.9	momentum-0.99	optimizer-adam_weight_decay	augment-translation_factor-0.0	translation_factor-0.0	augment-vertical_flip-True	vertical_flip-True	end_learning_rate-1e-5	optimizer-nadam	augment-contrast_factor-0.1	contrast_factor-0.1	pretrained-False	augment-horizontal_flip-False	horizontal_flip-False	reduction_type-global_max	augment-zoom_factor-0.0	dropout-0.25	zoom_factor-0.0	optimizer-adam	augment-rotation_factor-0.0	rotation_factor-0.0	normalize-True	augment-translation_factor-0.1	augment-horizontal_flip-True	augment-vertical_flip-False	augment-rotation_factor-0.1	augment-zoom_factor-0.1	augment-contrast_factor-0.0	reduction_type-global_avg	reduction_type-flatten	normalize-False	augment-False	imagenet_size-False	dropout-0.0	rotation_factor-0.1	zoom_factor-0.1	horizontal_flip-True	pretrained-True	contrast_factor-0.0	vertical_flip-False	translation_factor-0.1	block_type-vanilla	imagenet_size-True	block_type-efficient	learning_rate-0.1	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/
resnet-slow_converge-normal-normal	learning_rate-0.01	trainable-True	learning_rate-0.1	learning_rate-0.001	optimizer-adam_weight_decay	end_learning_rate-1e-5	optimizer-nadam	block_type-xception	optimizer-adam	learning_rate-0.0001	momentum-0.99	imagenet_size-True	momentum-0.9	learning_rate-2e-05	pretrained-False	dropout-0.5	dropout-0.25	reduction_type-global_max	normalize-True	reduction_type-global_avg	normalize-False	dropout-0.0	reduction_type-flatten	pretrained-True	learning_rate-1e-05	momentum-0.5	imagenet_size-False	momentum-0.1	optimizer-sgd	block_type-efficient	block_type-vanilla	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/
vanilla-normal-dying-normal	block_type-xception	filters_1_0-256	optimizer-adam_weight_decay	end_learning_rate-1e-5	optimizer-nadam	learning_rate-0.001	max_pooling-True	block_type-resnet	dropout-0.5	vertical_flip-False	filters_2_0-512	filters_2_0-256	separable-False	rotation_factor-0.0	filters_2_0-128	filters_0_0-512	filters_0_1-128	zoom_factor-0.1	kernel_size-5	activation-selu	initial-he_uniform	reduction_type-global_max	num_layers-2	activation-tanh	initial-lecun_uniform	augment-translation_factor-0.0	augment-horizontal_flip-True	augment-vertical_flip-False	augment-rotation_factor-0.0	augment-zoom_factor-0.1	augment-contrast_factor-0.1	normalize-False	filters_0_0-128	dropout-0.25	filters_2_0-64	augment-horizontal_flip-False	augment-translation_factor-0.1	kernel_size-7	contrast_factor-0.1	reduction_type-global_avg	filters_1_1-32	num_blocks-3	filters_1_1-256	augment-contrast_factor-0.0	translation_factor-0.0	horizontal_flip-True	filters_0_0-64	learning_rate-0.0001	filters_0_1-256	filters_1_1-64	horizontal_flip-False	translation_factor-0.1	filters_0_1-64	num_blocks-2	filters_1_0-128	filters_1_1-512	filters_0_1-32	augment-zoom_factor-0.0	filters_0_1-16	reduction_type-flatten	filters_0_0-16	contrast_factor-0.0	kernel_size-3	augment-rotation_factor-0.1	filters_0_0-32	filters_1_1-128	normalize-True	augment-False	filters_2_0-32	num_layers-1	filters_1_1-16	filters_2_0-16	filters_1_0-64	augment-vertical_flip-True	zoom_factor-0.0	filters_0_1-512	filters_0_0-256	rotation_factor-0.1	optimizer-adam	separable-True	dropout-0.0	filters_1_0-32	vertical_flip-True	filters_1_0-16	max_pooling-False	learning_rate-2e-05	momentum-0.99	momentum-0.9	num_blocks-1	block_type-efficient	learning_rate-1e-05	momentum-0.5	momentum-0.1	optimizer-sgd	learning_rate-0.01	filters_1_0-512	learning_rate-0.1	/	/	/	/	/	/
vanilla-normal-explode-nan_weight	num_blocks-1	num_layers-2	optimizer-sgd	block_type-xception	momentum-0.1	separable-True	learning_rate-0.1	momentum-0.5	momentum-0.9	momentum-0.99	augment-False	block_type-resnet	vertical_flip-False	kernel_size-5	reduction_type-global_max	dropout-0.5	max_pooling-False	rotation_factor-0.0	initial-lecun_uniform	activation-tanh	dropout-0.25	translation_factor-0.0	contrast_factor-0.1	filters_0_0-512	initial-he_uniform	kernel_size-3	activation-selu	normalize-True	horizontal_flip-True	learning_rate-0.01	filters_0_1-512	zoom_factor-0.1	filters_0_0-128	optimizer-adam_weight_decay	optimizer-nadam	end_learning_rate-1e-5	zoom_factor-0.0	filters_0_1-32	augment-vertical_flip-False	filters_0_1-128	filters_0_1-64	horizontal_flip-False	normalize-False	filters_0_0-256	dropout-0.0	translation_factor-0.1	contrast_factor-0.0	rotation_factor-0.1	max_pooling-True	filters_0_1-16	filters_0_0-32	filters_0_0-64	reduction_type-global_avg	reduction_type-flatten	kernel_size-7	filters_0_1-256	augment-translation_factor-0.0	augment-contrast_factor-0.1	augment-horizontal_flip-True	vertical_flip-True	augment-translation_factor-0.1	augment-horizontal_flip-False	augment-vertical_flip-True	augment-rotation_factor-0.0	augment-zoom_factor-0.1	augment-contrast_factor-0.0	augment-zoom_factor-0.0	learning_rate-0.001	augment-rotation_factor-0.1	block_type-efficient	filters_0_0-16	learning_rate-0.0001	learning_rate-1e-05	learning_rate-2e-05	separable-False	num_blocks-2	num_blocks-3	num_layers-1	optimizer-adam	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/
vanilla-normal-normal-normal	block_type-xception	separable-False	optimizer-adam_weight_decay	end_learning_rate-1e-5	dropout-0.5	optimizer-nadam	block_type-resnet	reduction_type-global_max	learning_rate-0.001	augment-False	vertical_flip-False	num_layers-1	filters_1_0-512	filters_1_1-512	filters_2_0-512	num_blocks-2	rotation_factor-0.0	activation-tanh	learning_rate-0.01	initial-he_uniform	filters_0_0-512	activation-selu	filters_1_0-256	initial-lecun_uniform	filters_2_1-512	translation_factor-0.0	filters_1_1-256	max_pooling-False	filters_2_1-256	filters_1_0-128	kernel_size-5	filters_2_0-256	filters_2_1-128	filters_0_0-256	filters_2_0-64	filters_2_0-128	horizontal_flip-False	filters_0_1-512	filters_1_0-64	normalize-False	kernel_size-7	dropout-0.25	zoom_factor-0.1	filters_1_1-128	contrast_factor-0.0	zoom_factor-0.0	filters_2_1-64	num_blocks-1	contrast_factor-0.1	normalize-True	horizontal_flip-True	filters_1_1-64	filters_0_0-128	dropout-0.0	filters_0_1-128	filters_0_1-256	filters_0_0-64	filters_0_1-64	optimizer-adam	filters_0_0-32	max_pooling-True	filters_0_1-32	translation_factor-0.1	filters_2_0-16	kernel_size-3	filters_0_1-16	filters_2_0-32	learning_rate-0.0001	rotation_factor-0.1	filters_1_0-16	filters_1_1-16	filters_2_1-16	augment-rotation_factor-0.0	augment-vertical_flip-False	filters_1_0-32	reduction_type-global_avg	filters_0_0-16	augment-translation_factor-0.0	filters_1_1-32	num_layers-2	vertical_flip-True	reduction_type-flatten	num_blocks-3	augment-horizontal_flip-False	augment-contrast_factor-0.0	augment-contrast_factor-0.1	filters_2_1-32	augment-horizontal_flip-True	augment-zoom_factor-0.1	augment-zoom_factor-0.0	momentum-0.99	augment-rotation_factor-0.1	augment-translation_factor-0.1	momentum-0.9	augment-vertical_flip-True	momentum-0.5	learning_rate-2e-05	momentum-0.1	optimizer-sgd	block_type-efficient	learning_rate-1e-05	separable-True	learning_rate-0.1
vanilla-slow_converge-dying-normal	block_type-xception	learning_rate-0.01	learning_rate-0.001	optimizer-sgd	momentum-0.1	momentum-0.5	learning_rate-0.0001	num_layers-1	learning_rate-2e-05	num_blocks-2	momentum-0.9	learning_rate-1e-05	momentum-0.99	separable-False	filters_2_1-512	augment-rotation_factor-0.0	rotation_factor-0.0	filters_1_1-32	filters_2_1-64	augment-horizontal_flip-False	horizontal_flip-False	num_blocks-1	block_type-resnet	filters_1_1-256	optimizer-adam	kernel_size-5	max_pooling-True	filters_1_0-64	filters_0_0-16	filters_1_0-16	normalize-True	filters_1_0-128	filters_1_1-512	optimizer-adam_weight_decay	reduction_type-global_max	end_learning_rate-1e-5	optimizer-nadam	reduction_type-global_avg	kernel_size-3	dropout-0.25	dropout-0.0	kernel_size-7	filters_0_0-32	filters_0_0-64	filters_0_0-128	filters_0_0-256	filters_0_0-512	filters_0_1-16	filters_0_1-128	filters_0_1-32	filters_0_1-64	filters_0_1-256	filters_0_1-512	filters_1_0-32	filters_1_0-256	filters_1_0-512	filters_2_0-16	filters_2_0-512	filters_2_0-32	filters_2_0-64	filters_2_0-128	filters_2_0-256	filters_1_1-16	filters_1_1-128	filters_2_1-16	filters_2_1-32	filters_2_1-128	filters_2_1-256	augment-False	augment-translation_factor-0.1	augment-translation_factor-0.0	augment-horizontal_flip-True	augment-vertical_flip-True	augment-vertical_flip-False	augment-rotation_factor-0.1	augment-zoom_factor-0.0	augment-zoom_factor-0.1	augment-contrast_factor-0.0	augment-contrast_factor-0.1	translation_factor-0.0	translation_factor-0.1	vertical_flip-False	vertical_flip-True	zoom_factor-0.1	zoom_factor-0.0	contrast_factor-0.1	contrast_factor-0.0	dropout-0.5	activation-selu	activation-tanh	initial-he_uniform	initial-lecun_uniform	reduction_type-flatten	filters_1_1-64	normalize-False	max_pooling-False	horizontal_flip-True	rotation_factor-0.1	separable-True	learning_rate-0.1	block_type-efficient	num_blocks-3	num_layers-2
vanilla-slow_converge-explode-nan_weight	num_blocks-3	block_type-xception	num_layers-2	separable-True	reduction_type-global_max	reduction_type-global_avg	max_pooling-True	block_type-resnet	normalize-True	normalize-False	kernel_size-5	kernel_size-3	kernel_size-7	num_blocks-2	filters_0_0-16	filters_0_0-128	filters_0_0-32	filters_0_0-64	filters_0_0-256	filters_0_0-512	filters_0_1-16	filters_0_1-512	filters_0_1-32	filters_0_1-64	filters_0_1-128	filters_0_1-256	filters_1_0-16	filters_1_0-512	filters_1_0-32	filters_1_0-64	filters_1_0-128	filters_1_0-256	filters_1_1-16	filters_1_1-256	filters_1_1-32	filters_1_1-64	filters_1_1-128	block_type-efficient	filters_1_1-512	max_pooling-False	reduction_type-flatten	separable-False	num_layers-1	num_blocks-1	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/
vanilla-slow_converge-normal-normal	block_type-xception	optimizer-adam_weight_decay	end_learning_rate-1e-5	optimizer-nadam	learning_rate-0.01	learning_rate-0.1	optimizer-adam	block_type-resnet	learning_rate-0.001	separable-False	learning_rate-0.0001	reduction_type-global_max	augment-contrast_factor-0.1	filters_1_1-64	contrast_factor-0.1	kernel_size-5	num_layers-1	rotation_factor-0.1	dropout-0.5	kernel_size-3	filters_1_0-32	filters_0_0-32	num_blocks-2	filters_0_1-16	augment-rotation_factor-0.1	filters_0_1-512	augment-zoom_factor-0.1	num_blocks-3	filters_0_0-16	reduction_type-global_avg	contrast_factor-0.0	vertical_flip-False	filters_0_0-64	augment-zoom_factor-0.0	translation_factor-0.0	max_pooling-True	augment-translation_factor-0.0	filters_0_1-64	horizontal_flip-False	augment-False	zoom_factor-0.1	augment-contrast_factor-0.0	augment-vertical_flip-False	filters_0_1-32	learning_rate-1e-05	filters_0_1-128	filters_1_1-16	filters_0_0-512	normalize-True	filters_1_0-64	filters_1_0-128	filters_1_0-512	activation-selu	activation-tanh	initial-he_uniform	initial-lecun_uniform	augment-horizontal_flip-False	filters_1_0-256	filters_1_1-32	filters_1_1-512	filters_1_0-16	augment-translation_factor-0.1	filters_1_1-256	normalize-False	filters_0_0-256	filters_0_0-128	learning_rate-2e-05	num_blocks-1	reduction_type-flatten	zoom_factor-0.0	augment-vertical_flip-True	augment-horizontal_flip-True	horizontal_flip-True	filters_1_1-128	augment-rotation_factor-0.0	max_pooling-False	dropout-0.25	translation_factor-0.1	vertical_flip-True	filters_0_1-256	dropout-0.0	kernel_size-7	rotation_factor-0.0	num_layers-2	separable-True	momentum-0.99	momentum-0.9	block_type-efficient	momentum-0.5	momentum-0.1	optimizer-sgd	/	/	/	/	/	/	/	/	/	/	/	/
xception-normal-normal-normal	trainable-True	imagenet_size-True	pretrained-True	optimizer-adam_weight_decay	dropout-0.5	end_learning_rate-1e-5	learning_rate-0.0001	reduction_type-global_max	multi_step-True	reduction_type-global_avg	optimizer-adam	triple_train-True	dropout-0.25	block_type-efficient	imagenet_size-False	block_type-resnet	optimizer-nadam	step_1_freeze-all	learning_rate-0.001	pretrained-False	step_1_freeze-bn	step_1_freeze-no	dropout-0.0	normalize-True	step_2_lr_scale-1.0	momentum-0.99	normalize-False	momentum-0.9	step_1_ratio-0.2	end_learning_rate-2e-06	weight_decay_rate-0.01	end_learning_rate-0.0	weight_decay_rate-0.1	weight_decay_rate-0.001	end_learning_rate-0.0001	step_1_ratio-0.3	step_1_ratio-0.1	weight_decay_rate-0.05	end_learning_rate-1e-06	weight_decay_rate-0.005	step_1_ratio-0.5	reduction_type-flatten	step_1_ratio-0.4	triple_train-False	momentum-0.5	learning_rate-2e-05	momentum-0.1	optimizer-sgd	step_2_lr_scale-0.1	learning_rate-0.01	step_2_lr_scale-0.01	learning_rate-1e-05	learning_rate-0.1	block_type-vanilla	trainable-False	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/	/